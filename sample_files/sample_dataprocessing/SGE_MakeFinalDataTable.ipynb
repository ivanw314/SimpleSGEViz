{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook builds all supplementary tables required for regenerating figures. A single, multi-tabbed excel file will be output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SGE Score Files\n",
    "del_file = './Data/supp_table_inputs/20251002_BARD1delscores.tsv' #BARD1 3bp deletion scores\n",
    "snv_file = './Data/supp_table_inputs/20251002_BARD1snvscores.tsv' #BARD1 SNV scores\n",
    "thresholds = './Data/supp_table_inputs/20251002_BARD1modelparams.tsv' #SGE pipeline output thresholds\n",
    "\n",
    "#ClinVar Files\n",
    "clinvar_snvs_file = './Data/supp_table_inputs/20250912_BARD1_ClinVarSNVs_1StarPlus.txt' #ClinVar SNVs, at least 1 star review status, accessed 2025/09/12\n",
    "clinvar_dels_file = './Data/supp_table_inputs/20250912_BARD1_ClinVarDels_1StarPlus.txt' #ClinVar Deletions, at least 1 star review status, accessed 2025/09/12\n",
    "\n",
    "#Allele Frequency Files\n",
    "gnom_path = './Data/supp_table_inputs/20240905_BARD1_gnomADv4.1.0_SNVs.xlsx' #gnomAD v4.1.0 SNVs, accessed 2024/09/05\n",
    "reg_path = './Data/supp_table_inputs/20240802_BARD1_Regeneron_MAF.xlsx' #Regeneron Million Exome allele frequency data. Accessed 2024/08/02\n",
    "\n",
    "#Normalized Depth Files\n",
    "read_depth_path = './Data/supp_table_inputs/depth_data/depth_files'\n",
    "aa_annotation_file = './Data/supp_table_inputs/20260218_BARD1_pos_aapos.tsv'\n",
    "gsp_input_file = './Data/supp_table_inputs/depth_data/deletion_inputs.xlsx'\n",
    "target_coords = './Data/supp_table_inputs/20250415_BARD1_filter_entry.xlsx'\n",
    "cut_sites = './Data/supp_table_inputs/20241217_BARD1_sgRNA_cutsites.xlsx'\n",
    "\n",
    "#Misc. Annotations\n",
    "snv_counts = './Data/supp_table_inputs/20250825_BARD1counts.tsv' #Counts for assayed SNVs\n",
    "vep_predictions = './Data/supp_table_inputs/20251002_BARD1snvs_VEP.xlsx' #VEP annotated file\n",
    "mutpred_prediction = './Data/supp_table_inputs/20251006_BARD1_MutPred2.xlsx' #MutPred2 scores\n",
    "atg_scores = './Data/supp_table_inputs/ATG_lib_data/20250409_BARD1_X1A_ATG_scored.xlsx' #ATG score file\n",
    "rna_scores = './Data/supp_table_inputs/20250922_BARD1RNAscores.tsv' #RNA scores\n",
    "phylop = './Data/supp_table_inputs/20251008_PhyloP.xlsx' #PhyloP scores\n",
    "edit_rate = './Data/supp_table_inputs/20250926_BARD1.editrates.sorted.tsv' #Editing rates for useable reads file\n",
    "orthogonal_assays = './Data/supp_table_inputs/20241016_Orthogonal_BARD1_FunctionalAssays.xlsx' #Curated orthogonal BARD1 assays\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Functions for initial read in of SGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(snv, thresholds): #Gets SGE thresholds\n",
    "    df = pd.read_csv(thresholds, sep = '\\t')\n",
    "\n",
    "    \n",
    "    thresholds = [df['thresh_abnormal'][0], df['thresh_normal'][0]]\n",
    "\n",
    "\n",
    "    df = pd.read_csv(snv, sep = '\\t')\n",
    "    #Some quick processing of SNV scores\n",
    "    df.loc[df['score'] >= 0, 'functional_consequence'] = 'functionally_normal' #Ensures that variants above our upper threshold (which is less than 0) will be assigned a functionally normal class\n",
    "    df['var_type'] = 'snv' #Sets variant type column to SNV\n",
    "    df['pos'] = df['pos'].astype(int)\n",
    "    df['start'] = df['pos']\n",
    "    df['end'] = df['pos']\n",
    "    df['pos_id'] = df['pos'].astype(str) + ':' + df['alt']\n",
    "    df = df[(df['variant_qc_flag'] != 'WARN')]\n",
    "    return df, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_dels(dels, thresholds):\n",
    "    dels = pd.read_csv(dels, sep = '\\t') #Reads deletions\n",
    "    \n",
    "    dels['var_type'] = '3bp_del'\n",
    "    dels['start'] = dels['pos'] + 1\n",
    "    dels['end'] = dels['pos'] + 3\n",
    "    dels['pos_id'] = dels['start'].astype(str) + \"-\" + dels['end'].astype(str)\n",
    "    \n",
    "    dels = dels.astype({'pos': int,\n",
    "                       'start': int,\n",
    "                       'end': int})\n",
    "    \n",
    "    return dels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Function used to process and merge RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rna(rna):\n",
    "    df = pd.read_csv(rna, sep = '\\t')\n",
    "    df = df.loc[~np.isinf(df['RNA_DNA_log2'])]\n",
    "\n",
    "\n",
    "    df = df[['pos_id', 'RNA_DNA_log2', 'exon', 'consequence']]\n",
    "\n",
    "    df = df.rename(columns = {'RNA_DNA_log2': 'RNAscore'})\n",
    "\n",
    "    df = df.groupby('pos_id').agg({\n",
    "        'RNAscore': 'mean',\n",
    "        'consequence': 'first',\n",
    "        'exon': 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    class_df = df.loc[df['consequence'].isin(['stop_gained'])]\n",
    "    class_df = class_df.copy()\n",
    "\n",
    "    class_df = class_df.loc[~class_df['exon'].isin(['BARD1_X1', 'BARD1_X2', 'BARD1_X11'])]\n",
    "    percentiles = class_df['RNAscore'].quantile(0.975)\n",
    "\n",
    "    class_df = class_df.loc[class_df['RNAscore'] <= percentiles]\n",
    "    \n",
    "\n",
    "    mean_stop = class_df['RNAscore'].mean()\n",
    "  \n",
    "    mean_std = class_df['RNAscore'].std()\n",
    "\n",
    "    lwrthresh = mean_stop  +  mean_std\n",
    " \n",
    "\n",
    "    df['RNA_consequence'] = 'normal'\n",
    "    df.loc[df['RNAscore'] <= lwrthresh, 'RNA_consequence'] = 'low'\n",
    "\n",
    "    df = df[['pos_id', 'RNAscore', 'RNA_consequence']]\n",
    "\n",
    "    return df, lwrthresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Functions used to process and merge the ClinVar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clinvar(snv_file, del_file, show_del_stats = False): #Reads ClinVar data\n",
    "    \n",
    "    df = pd.read_csv(snv_file, delimiter='\\t') #reads ClinVar SNV tabular .txt \n",
    "    df = df[['Name','Protein change','GRCh38Chromosome','GRCh38Location','Germline classification']] #pulls useful columns\n",
    "    df = df.dropna(subset = ['GRCh38Location']) #Drops variants without genomic coordinate\n",
    "    df.GRCh38Location = df.GRCh38Location.astype(int) #Sets coordinates to integer data type\n",
    "    df['pos_id'] = None #preps for next function\n",
    "\n",
    "\n",
    "    del_df = pd.read_csv(del_file, sep = '\\t') #Reads ClinVar deletions\n",
    "    del_df = del_df.loc[del_df['GRCh38Location'].str.contains('-')] #Splits coordinates\n",
    "    del_df['start'] = del_df['GRCh38Location'].transform(lambda x: x.split(' - ')[0]) #Gets deletion start coordinate\n",
    "    del_df['end'] = del_df['GRCh38Location'].transform(lambda x: x.split(' - ')[1]) #Gets deletion end coordinate\n",
    "\n",
    "    #Sets coordinate data types to integer\n",
    "    del_df['start'] = del_df['start'].astype(int) \n",
    "    del_df['end'] = del_df['end'].astype(int)\n",
    "\n",
    "    del_df['del_length'] = del_df['end'] - del_df['start'] #Calculates deletion length \n",
    "\n",
    "    del_df = del_df.loc[del_df['del_length'].isin([2])] #Pulls out 3bp deletions\n",
    "    del_df['pos_id'] = del_df['start'].astype(str) + '-' + del_df['end'].astype(str) #Sets base change column to coordinate spanned by deletion\n",
    "    del_df = del_df[['pos_id', 'Germline classification']] #Pulls out necessary columns\n",
    "\n",
    "\n",
    "    if show_del_stats:\n",
    "        #This block is used to give some quick ClinVar stats about the 3bp dels\n",
    "        print(f' This is all 3bp deletions in the ClinVar file: \\n {del_df}')\n",
    "        print(f' There are {len(del_df)} deletions')\n",
    "        print(f' Here are summary stats for each classification: {del_df[\"Germline classification\"].value_counts()}')\n",
    "\n",
    "    \n",
    "    return df, del_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair(base): #ClinVar gives base changes on negative sense strand, SGE pos_id on positive sense\n",
    "    if base == 'A':\n",
    "        return 'T'\n",
    "    elif base == 'T':\n",
    "        return 'A'\n",
    "    elif base == 'C':\n",
    "        return 'G'\n",
    "    else:\n",
    "        return 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_changes(df): #Creates pos_id column in format of SGE datafile for ClinVar data    \n",
    "    k = 0\n",
    "    while k < len(df):\n",
    "        var = df['Name'][k]\n",
    "        coord = str(df['GRCh38Location'][k])\n",
    "        k += 1\n",
    "        i = 0\n",
    "        j = 3\n",
    "        while j < (len(var) + 1):\n",
    "            test_str = var[i:j]\n",
    "            j += 1\n",
    "            i += 1\n",
    "            sense_base = get_pair(test_str[2])\n",
    "            if test_str[1] == '>':\n",
    "                change = coord + \":\" + sense_base\n",
    "                df.loc[df['Name'] == var, 'pos_id'] = change\n",
    "                \n",
    "    df = df[['pos_id', 'Germline classification']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Functions used to merge allele frequency data from gnomAD and Regeneron Million Exomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gnomAD(gnomAD_path): #Reads gnomAD file\n",
    "    \n",
    "    unfiltered = pd.read_excel(gnomAD_path) #Reads gnomAD file\n",
    "    filtered = unfiltered[['gnomAD ID', 'Allele Frequency']] #Gets necessary columns \n",
    "\n",
    "    filtered = filtered.copy()\n",
    "    filtered['pos_id'] = filtered['gnomAD ID'].transform(lambda x: x[2:11] + ':' + x[14]) #Adds pos_id column for merging\n",
    "\n",
    "    filtered = filtered.rename(columns = {'Allele Frequency': 'gnomad_af'})\n",
    "    filtered = filtered[['pos_id', 'gnomad_af']]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_regeneron(reg_path): #Reads Regeneron data\n",
    "    \n",
    "    df = pd.read_excel(reg_path) #Reads data\n",
    "    maf = df[['Variant','AAF']] #Pulls necessary columns\n",
    "    maf = maf.copy()\n",
    "\n",
    "    maf = maf.rename(columns = {'AAF': 'regeneron_maf', 'Variant': 'pos_id'}) #Renames columns to share column names with SGE data\n",
    "\n",
    "    maf['pos_id'] = maf['pos_id'].transform(lambda x: x[2:12] + x[len(x) - 1: len(x) + 1]) #Remakes the pos_id column to match pos_id column from SGE data for merging\n",
    "    \n",
    "    return maf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Function to add SNV counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_counts(counts):\n",
    "    counts_df = pd.read_csv(counts, sep = '\\t')\n",
    "\n",
    "    counts_df['pos_id'] = counts_df['pos'].astype(str) + ':' + counts_df['alt']\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Fuction to add variant effect predictor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vep(file, mutpred_file):\n",
    "    vep_df = pd.read_excel(file)\n",
    "    mutpred_df = pd.read_excel(mutpred_file)\n",
    "\n",
    "    vep_df['pos'] = vep_df['Location'].transform(lambda x: x[-9:])\n",
    "    vep_df['pos_id'] = vep_df['pos'] + ':' + vep_df['Allele']\n",
    "    vep_df = vep_df.drop(columns = ['Location', 'Allele', 'pos', 'REVEL'])\n",
    "    \n",
    "    vep_df['max_SpliceAI'] = vep_df[['SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL', 'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']].max(axis = 1)\n",
    "    vep_df = vep_df.rename(columns = {'SpliceAI_pred_DS_AG': 'SpliceAI_AG', \n",
    "                                      'SpliceAI_pred_DS_AL':'SpliceAI_AL',\n",
    "                                      'SpliceAI_pred_DS_DG': 'SpliceAI_DG',\n",
    "                                      'SpliceAI_pred_DS_DL': 'SpliceAI_DL',\n",
    "                                      'am_pathogenicity': 'am_score',\n",
    "                                      'CADD_PHRED': 'cadd_score'\n",
    "                                     })\n",
    "\n",
    "    mutpred_df = mutpred_df[['hg38_start', 'alt_allele', 'MutPred2', 'REVEL', 'REVEL_train', 'MP2_train']]\n",
    "    mutpred_df['pos_id'] = mutpred_df['hg38_start'].astype(str) + ':' + mutpred_df['alt_allele']\n",
    "    \n",
    "    mutpred_df = mutpred_df[['pos_id', 'MutPred2', 'REVEL', 'REVEL_train', 'MP2_train']]\n",
    "\n",
    "    mutpred_df = mutpred_df.rename(columns = {'REVEL': 'revel_score',\n",
    "                                             'MP2_train': 'MutPred2_train'})\n",
    "    \n",
    "    vep_df = vep_df[['pos_id', 'SpliceAI_AG', 'SpliceAI_AL', 'SpliceAI_DG', 'SpliceAI_DL', 'max_SpliceAI', 'am_score', 'cadd_score']]\n",
    "    \n",
    "    vep_df = pd.merge(vep_df, mutpred_df, on = 'pos_id', how = 'left')\n",
    "    \n",
    "    return vep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Functions to add median normalized depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(file, cut_sites): #Reads input file containing coordinates for all exons\n",
    "    \n",
    "    input_params = pd.read_excel(file) #Reads input file\n",
    "\n",
    "    #Loop that creates list of genomic coordinates for coding sequence\n",
    "    i = 0\n",
    "    cds_coords = [] #List to hold coding coordinates\n",
    "    while i < len(input_params):\n",
    "        start = input_params['start'][i] #Gets starting coordinate\n",
    "        end = input_params['end'][i] #Gets end coordinate\n",
    "\n",
    "        #Makes coding coordinates\n",
    "        for j in range(start, end + 1):\n",
    "            cds_coords.append(j)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    cut_sites = pd.read_excel(cut_sites)\n",
    "    cut_sites.set_index('target', inplace = True)\n",
    "\n",
    "    return cds_coords, cut_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_depth(depth_path, annotation_file,coding_coords, target_coords, cut_df): #Processes all depth files in directory and annotates them\n",
    "    \n",
    "    file_path = Path(depth_path) #Creates path object for depth files \n",
    "\n",
    "    depth_files = sorted(list(file_path.glob('*.tsv'))) #Gets all depth files\n",
    "    \n",
    "    columns = ['region', 'offset', 'depth'] #Column names for renaming depth files\n",
    "    \n",
    "    target_coordinates = pd.read_excel(target_coords, sheet_name = 'targets') #Reads input with SGE target coordinates\n",
    "    target_coordinates.set_index('target', inplace = True) #Sets target name to index\n",
    "\n",
    "    all_dfs = [] #Empty list to hold processed dataframes\n",
    "\n",
    "    #For loop iterates through all depth files and processes them\n",
    "    for file in depth_files:\n",
    "        df = pd.read_csv(file, sep = '\\t') #Reads depth file\n",
    "        df = df.set_axis(columns, axis = 1) #Renames columns \n",
    "\n",
    "        min_depth = df['depth'].min() #Gets minimum read count in file\n",
    "        max_depth = df['depth'].max() #Gets maximum read count in file\n",
    "\n",
    "        df['normdepth'] = df['depth'] / max_depth #Calculates normalized depth based on proportion of maximum read counts \n",
    "\n",
    "        full_region = df['region'][0] #Gets full SGE target\n",
    "        region_start = int(re.findall(r':(\\d+)-', full_region)[0]) #Gets starting coordinate for sequencing amplicon \n",
    "\n",
    "        df['pos'] = region_start + df['offset'] - 1 #Generates genomic coordinates for all regions based on offset column and starting coordinate\n",
    "\n",
    "        file_str = str(file) #Sets file name to string data type\n",
    "        region_rep = re.findall(r'/([^/]+)_D13\\.depth\\.tsv$', file_str)[0] #Gets region and replicate string\n",
    "\n",
    "        region_rep_split = region_rep.split('_') #Splits string on '_'\n",
    "        target = region_rep_split[0] + '_' + region_rep_split[1] #Gets target name\n",
    "        exon_test = region_rep_split[1][1:-1] #Gets exon \n",
    "\n",
    "        region_start = target_coordinates.loc[target, 'end'] #Gets SGE target starting coordinate\n",
    "        region_end = target_coordinates.loc[target, 'start'] #Gets SGE target end coordinate (end/start flipped due to antisense gene)\n",
    "    \n",
    "        region_coords = [] #List to hold coordinates in SGE target\n",
    "\n",
    "        for k in range(region_start, region_end + 1): #Loop creates coordinates for SGE target\n",
    "            region_coords.append(k)\n",
    "\n",
    "        #Booleans to get name of exon\n",
    "        if len(exon_test) > 0: #tests for all regions but X2\n",
    "            exon = exon_test\n",
    "        else: #Exception for X2\n",
    "            exon = '2'\n",
    "            \n",
    "        full_rep = region_rep_split[2] #Gets replicate value\n",
    "\n",
    "        #Boolean tests to assign replicate number\n",
    "        if full_rep == 'R1R4' or full_rep == 'R1R2R3':\n",
    "            rep = 'R1'\n",
    "        elif full_rep == 'R2R5' or full_rep == 'R4R5R6':\n",
    "            rep = 'R2'\n",
    "        elif full_rep == 'R3R6' or full_rep == 'R7R8R9':\n",
    "            rep = 'R3'\n",
    "\n",
    "        cut_site = cut_df.loc[target, 'pos']\n",
    "        \n",
    "        #Sets columns with identifying information\n",
    "        df['target'] = target\n",
    "        df['exon'] = exon\n",
    "        df['repl'] = rep\n",
    "        df['day'] = 'D13'\n",
    "        \n",
    "        df = df.loc[df['pos'].isin(region_coords)] #Dataframe filtered for coordinates in SGE target edited region only\n",
    "\n",
    "        df['cut_site_distance'] = -(df['pos'] - cut_site)\n",
    "         \n",
    "        all_dfs.append(df) #Dataframe appended to list\n",
    "    \n",
    "    final_df = pd.concat(all_dfs) #All dataframes concatenated\n",
    "    final_df = final_df.loc[final_df['pos'].isin(coding_coords)] #Dataframes filtered for coding sequencing only \n",
    "\n",
    "    annotation_df = pd.read_csv(annotation_file, sep = '\\t') #Reads amino acid annotation file\n",
    "\n",
    "    final_df = pd.merge(final_df, annotation_df, on = 'pos', how = 'left') #Depth and annotation_df merged to annotate with amino acids\n",
    "    \n",
    "    final_df['id'] = final_df['pos']  + final_df['depth']  + final_df['normdepth'] #Unique ID created for each datapoint \n",
    "\n",
    "    final_df = final_df.drop_duplicates(subset = 'id', keep = 'first') #Any duplicates dropped\n",
    "    final_df = final_df.drop(columns = ['id']) #ID column dropped \n",
    "\n",
    "    final_df = final_df.rename(columns = {'Aapos': 'amino_acid'}) #Amino acid annotation column renamed for merging with SGE scores later on\n",
    "    return final_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_read_depth(df): #Depth dataframe processed for visualization\n",
    "\n",
    "    df['pos'] = df['pos'].astype(str) #Sets 'pos' column to string datatype\n",
    "    df['target_id'] = df['target'] + ':' + df['pos'] #Builds a target ID column for target-based collapsing to median\n",
    "    grouped = df.groupby('target_id') #Groups dataframe by target ID\n",
    "\n",
    "    #Creates dataframe with annotated CDS positions\n",
    "    cds_annotated = df.groupby('pos').agg({ #Grouping by position allows for accurate CDS pos. to be assigned\n",
    "    'normdepth': 'median', \n",
    "    'target': 'first',\n",
    "    'exon': 'first',\n",
    "    'amino_acid': 'last'\n",
    "    }).reset_index()\n",
    "\n",
    "    \n",
    "    cds_pos = [] #List to hold CDS position values\n",
    "\n",
    "    for i in range(len(cds_annotated)): #Builds CDS position values\n",
    "        cds_pos.append(i+1)\n",
    "\n",
    "    cds_pos = cds_pos[::-1] #Reverses values due to negative sense gene\n",
    "\n",
    "    \n",
    "    \n",
    "    cds_annotated['CDSpos'] = cds_pos #Adds CDS position column\n",
    "    cds_annotated = cds_annotated[['pos', 'CDSpos']] #Drops unncessary column s\n",
    "    \n",
    "    #Collapses depth calculations to median based on shared target and position for all 3 replicates\n",
    "    median_depth = grouped.agg({\n",
    "        'normdepth': 'median',\n",
    "        'pos': 'first',\n",
    "        'target': 'first',\n",
    "        'exon': 'first',\n",
    "        'amino_acid': 'first',\n",
    "        'cut_site_distance': 'first'\n",
    "    }\n",
    "                              )\n",
    "\n",
    "    median_depth = pd.merge(median_depth, cds_annotated, on = 'pos', how = 'left') #Merges with CDS annotated dataframe with add CDS position\n",
    "    median_depth = median_depth.rename(columns = {'normdepth': 'median_depth'}) #depth column renamed \n",
    "    \n",
    "    median_depth['AApos'] = median_depth['amino_acid'].str[1:]\n",
    "\n",
    "    aa_grouped = median_depth.groupby('AApos')\n",
    "\n",
    "    min_depth_aa_level = aa_grouped.agg({\n",
    "        'median_depth': 'min',\n",
    "        'target': 'first', \n",
    "        'exon': 'first',\n",
    "        'amino_acid': 'first',\n",
    "    }\n",
    "                                          )\n",
    "    min_depth_aa_level = min_depth_aa_level.reset_index(names = ['AApos'])\n",
    "    \n",
    "    return median_depth, min_depth_aa_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(save = False):\n",
    "\n",
    "    #Reads SGE data\n",
    "    snv_df, snv_thresholds = get_thresholds(snv_file, thresholds)\n",
    "    del_df = class_dels(del_file, snv_thresholds)\n",
    "\n",
    "    sge_df = pd.concat([snv_df, del_df]) #Final concatenated SNVs and Deletions dataframe\n",
    "\n",
    "    #Reads and Merges RNA data\n",
    "    rna_df,rna_thresh = process_rna(rna_scores)\n",
    "\n",
    "    df = pd.merge(sge_df, rna_df, on = 'pos_id', how = 'left') #Merged with RNA scores and classifications\n",
    "\n",
    "\n",
    "    #Processes and Merges ClinVar Data\n",
    "    clinvar_snvs, clinvar_dels = read_clinvar(clinvar_snvs_file, clinvar_dels_file)\n",
    "    clinvar_snvs = get_base_changes(clinvar_snvs)\n",
    "    all_clinvar = pd.concat([clinvar_snvs, clinvar_dels])\n",
    "\n",
    "    df = pd.merge(df, all_clinvar, on = 'pos_id', how = 'left') #df merged with ClinVar\n",
    "\n",
    "    #Processes and Merges MAF Data\n",
    "    gnomad_df = read_gnomAD(gnom_path)\n",
    "    regeneron_df = read_regeneron(reg_path)\n",
    "\n",
    "    df = pd.merge(df, gnomad_df, on = 'pos_id', how = 'left')\n",
    "    df = pd.merge(df, regeneron_df, on = 'pos_id', how = 'left')\n",
    "\n",
    "    #Merge in SNV counts\n",
    "    counts_df = read_counts(snv_counts)\n",
    "\n",
    "    #Merge PhyloP data\n",
    "    phylop_df = pd.read_excel(phylop)\n",
    "    phylop_df['pos'] = phylop_df['pos'].astype(int)\n",
    "    phylop_df = phylop_df.drop_duplicates(subset = ['phyloP'])\n",
    "    df = pd.merge(df, phylop_df, on = 'pos', how = 'left')\n",
    "\n",
    "    #Adds VEP data\n",
    "    vep_df = read_vep(vep_predictions, mutpred_prediction)\n",
    "\n",
    "    df = pd.merge(df, vep_df, on = 'pos_id', how = 'left')\n",
    "\n",
    "    #Calculates and adds normalized read depth for each position\n",
    "    coding_coords, cut_coords = read_input(gsp_input_file, cut_sites)\n",
    "    all_reps_depth = process_depth(read_depth_path, aa_annotation_file, coding_coords, target_coords, cut_coords)\n",
    "    collapsed_depth, min_collapsed_depth_aa = process_read_depth(all_reps_depth)\n",
    "\n",
    "\n",
    "    #Adds ATG data\n",
    "    atg_df = pd.read_excel(atg_scores)\n",
    "\n",
    "    \n",
    "    threshold_df = pd.DataFrame({'min': [snv_thresholds[0]], 'max': [snv_thresholds[1]], 'rna': [rna_thresh]})\n",
    "\n",
    "    #Adds edit rates\n",
    "    edit_df = pd.read_csv(edit_rate, sep = '\\t')\n",
    "\n",
    "    #Adds orthogonal assays\n",
    "    orthogonal_df = pd.read_excel(orthogonal_assays)\n",
    "\n",
    "    dfs = {'scores': df,\n",
    "           'snv_counts': counts_df,\n",
    "           'edit_rates': edit_df,\n",
    "           'thresholds': threshold_df,\n",
    "           'cutsites': cut_coords,\n",
    "           'median_pos_depth': collapsed_depth,\n",
    "           'min_aa_depth': min_collapsed_depth_aa,\n",
    "           'start_codon_scores': atg_df,\n",
    "           'orthogonal_data': orthogonal_df\n",
    "          }\n",
    "\n",
    "    print('Data file generated')\n",
    "    print(dfs)\n",
    "\n",
    "    if save:\n",
    "        print('Writing File...')\n",
    "    \n",
    "        with pd.ExcelWriter('./Data/final_tables/supplementary_file_1_BARD1_SGE_final_table.xlsx') as writer:\n",
    "            for sheet_name, df in dfs.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "      \n",
    "        print('File Successfully Written')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file generated\n",
      "{'scores':       chrom        pos   ref alt       exon      target  consequence  \\\n",
      "0      chr2  214728633     A   C  BARD1_X11  BARD1_X11D  UTR_variant   \n",
      "1      chr2  214728633     A   G  BARD1_X11  BARD1_X11D  UTR_variant   \n",
      "2      chr2  214728633     A   T  BARD1_X11  BARD1_X11D  UTR_variant   \n",
      "3      chr2  214728634     A   C  BARD1_X11  BARD1_X11D  UTR_variant   \n",
      "4      chr2  214728634     A   G  BARD1_X11  BARD1_X11D  UTR_variant   \n",
      "...     ...        ...   ...  ..        ...         ...          ...   \n",
      "10910  chr2  214809573  CCCG   C   BARD1_X1   BARD1_X1A  UTR_variant   \n",
      "10911  chr2  214809576  GCCT   G   BARD1_X1   BARD1_X1A  UTR_variant   \n",
      "10912  chr2  214809577  CCTT   C   BARD1_X1   BARD1_X1A  UTR_variant   \n",
      "10913  chr2  214809579  TTCG   T   BARD1_X1   BARD1_X1A  UTR_variant   \n",
      "10914  chr2  214809580  TCGG   T   BARD1_X1   BARD1_X1A  UTR_variant   \n",
      "\n",
      "          score  standard_error  95_ci_upper  ...  SpliceAI_AL SpliceAI_DG  \\\n",
      "0     -0.000149        0.012703     0.024749  ...          0.0         0.0   \n",
      "1      0.011140        0.019612     0.049579  ...          0.0         0.0   \n",
      "2     -0.008615        0.007645     0.006369  ...          0.0         0.0   \n",
      "3     -0.002724        0.016255     0.029136  ...          0.0         0.0   \n",
      "4      0.014382        0.019869     0.053324  ...          0.0         0.0   \n",
      "...         ...             ...          ...  ...          ...         ...   \n",
      "10910 -0.003289        0.004282     0.005104  ...          NaN         NaN   \n",
      "10911  0.008915        0.012361     0.033143  ...          NaN         NaN   \n",
      "10912  0.006988        0.007063     0.020832  ...          NaN         NaN   \n",
      "10913 -0.000332        0.005641     0.010724  ...          NaN         NaN   \n",
      "10914  0.005503        0.008829     0.022807  ...          NaN         NaN   \n",
      "\n",
      "      SpliceAI_DL max_SpliceAI am_score cadd_score  MutPred2  revel_score  \\\n",
      "0             0.0          0.0        -      8.179       NaN          NaN   \n",
      "1             0.0          0.0        -      8.416       NaN          NaN   \n",
      "2             0.0          0.0        -      8.490       NaN          NaN   \n",
      "3             0.0          0.0        -      4.303       NaN          NaN   \n",
      "4             0.0          0.0        -      4.483       NaN          NaN   \n",
      "...           ...          ...      ...        ...       ...          ...   \n",
      "10910         NaN          NaN      NaN        NaN       NaN          NaN   \n",
      "10911         NaN          NaN      NaN        NaN       NaN          NaN   \n",
      "10912         NaN          NaN      NaN        NaN       NaN          NaN   \n",
      "10913         NaN          NaN      NaN        NaN       NaN          NaN   \n",
      "10914         NaN          NaN      NaN        NaN       NaN          NaN   \n",
      "\n",
      "      REVEL_train MutPred2_train  \n",
      "0             NaN            NaN  \n",
      "1             NaN            NaN  \n",
      "2             NaN            NaN  \n",
      "3             NaN            NaN  \n",
      "4             NaN            NaN  \n",
      "...           ...            ...  \n",
      "10910         NaN            NaN  \n",
      "10911         NaN            NaN  \n",
      "10912         NaN            NaN  \n",
      "10913         NaN            NaN  \n",
      "10914         NaN            NaN  \n",
      "\n",
      "[10915 rows x 40 columns], 'snv_counts':       chrom        pos ref alt      target  snvlib_count  D05_R1  D05_R2  \\\n",
      "0      chr2  214809476   C   A   BARD1_X1A          2515    1199     823   \n",
      "1      chr2  214809476   C   G   BARD1_X1A          1938    1378     704   \n",
      "2      chr2  214809476   C   T   BARD1_X1A          1638     782     548   \n",
      "3      chr2  214809477   G   A   BARD1_X1A          1661     875     473   \n",
      "4      chr2  214809477   G   C   BARD1_X1A          1296     631     632   \n",
      "...     ...        ...  ..  ..         ...           ...     ...     ...   \n",
      "10802  chr2  214728734   G   C  BARD1_X11D          1403     291     293   \n",
      "10803  chr2  214728734   G   T  BARD1_X11D          1801     472     371   \n",
      "10804  chr2  214728735   G   A  BARD1_X11D          1241     259     311   \n",
      "10805  chr2  214728735   G   C  BARD1_X11D          1504     265     470   \n",
      "10806  chr2  214728735   G   T  BARD1_X11D          1945     363     349   \n",
      "\n",
      "       D05_R3  D13_R1  D13_R2  D13_R3       pos_id  \n",
      "0         806     845     849    1323  214809476:A  \n",
      "1         723    1050     826    1529  214809476:G  \n",
      "2         581     808     698     790  214809476:T  \n",
      "3         733     817     564     898  214809477:A  \n",
      "4         768     562     659    1082  214809477:C  \n",
      "...       ...     ...     ...     ...          ...  \n",
      "10802     360     326     673     585  214728734:C  \n",
      "10803     357     509     531     859  214728734:T  \n",
      "10804     328     223     471     378  214728735:A  \n",
      "10805     525     415     771     859  214728735:C  \n",
      "10806     524     636     864     925  214728735:T  \n",
      "\n",
      "[10807 rows x 13 columns], 'edit_rates':               target_rep  edit_rate\n",
      "0   BARD1_X4I_R7R8R9_D05   0.105312\n",
      "1    BARD1_X11C_R2R5_D05   0.119221\n",
      "2   BARD1_X4I_R4R5R6_D05   0.119939\n",
      "3   BARD1_X4F_R4R5R6_D05   0.120450\n",
      "4     BARD1_X4H_R3R6_D05   0.121311\n",
      "..                   ...        ...\n",
      "94  BARD1_X4G_R1R2R3_D05   0.307589\n",
      "95  BARD1_X4G_R4R5R6_D05   0.312754\n",
      "96  BARD1_X7A_R1R2R3_D05   0.344498\n",
      "97  BARD1_X7A_R4R5R6_D05   0.373571\n",
      "98   BARD1_X10B_R2R5_D05   0.398420\n",
      "\n",
      "[99 rows x 2 columns], 'thresholds':       min       max       rna\n",
      "0 -0.0615 -0.040588 -1.244705, 'cutsites':                   pos  AApos\n",
      "target                      \n",
      "BARD1_X1A   214809491     27\n",
      "BARD1_X1B   214809491     27\n",
      "BARD1_X2    214797066     70\n",
      "BARD1_X3A   214792399     88\n",
      "BARD1_X3B   214792363    100\n",
      "BARD1_X4A   214781493    127\n",
      "BARD1_X4B   214781425    150\n",
      "BARD1_X4C   214781318    186\n",
      "BARD1_X4D   214781298    192\n",
      "BARD1_X4E   214781162    238\n",
      "BARD1_X4F   214781033    281\n",
      "BARD1_X4G   214780998    292\n",
      "BARD1_X4H   214780883    331\n",
      "BARD1_X4I   214780856    340\n",
      "BARD1_X4J   214780718    386\n",
      "BARD1_X4K   214780665    403\n",
      "BARD1_X4L   214780619    419\n",
      "BARD1_X5A   214769298    441\n",
      "BARD1_X5B   214769247    461\n",
      "BARD1_X6A   214767624    476\n",
      "BARD1_X6B   214767540    504\n",
      "BARD1_X6C   214767501    517\n",
      "BARD1_X7A   214752531    531\n",
      "BARD1_X7B   214752464    554\n",
      "BARD1_X8A   214745810    575\n",
      "BARD1_X8B   214745758    592\n",
      "BARD1_X9A   214745137    611\n",
      "BARD1_X9B   214745115    619\n",
      "BARD1_X10A  214730451    654\n",
      "BARD1_X10B  214730435    659\n",
      "BARD1_X11A  214728960    684\n",
      "BARD1_X11B  214728858    718\n",
      "BARD1_X11C  214728828    728\n",
      "BARD1_X11D  214728699    771, 'median_pos_depth':       median_depth        pos      target exon amino_acid  cut_site_distance  \\\n",
      "0         0.987152  214730428  BARD1_X10A   10       L662                 23   \n",
      "1         0.984563  214730429  BARD1_X10A   10       R661                 22   \n",
      "2         0.983311  214730430  BARD1_X10A   10       R661                 21   \n",
      "3         0.982974  214730431  BARD1_X10A   10       R661                 20   \n",
      "4         0.983003  214730432  BARD1_X10A   10       S660                 19   \n",
      "...            ...        ...         ...  ...        ...                ...   \n",
      "2978      0.946205  214745119   BARD1_X9B    9       T617                 -4   \n",
      "2979      0.951783  214745120   BARD1_X9B    9       T617                 -5   \n",
      "2980      0.957459  214745121   BARD1_X9B    9       T617                 -6   \n",
      "2981      0.964556  214745122   BARD1_X9B    9       S616                 -7   \n",
      "2982      0.965009  214745123   BARD1_X9B    9       S616                 -8   \n",
      "\n",
      "      CDSpos AApos  \n",
      "0       1984   662  \n",
      "1       1983   661  \n",
      "2       1982   661  \n",
      "3       1981   661  \n",
      "4       1980   660  \n",
      "...      ...   ...  \n",
      "2978    1851   617  \n",
      "2979    1850   617  \n",
      "2980    1849   617  \n",
      "2981    1848   616  \n",
      "2982    1847   616  \n",
      "\n",
      "[2983 rows x 8 columns], 'min_aa_depth':     AApos  median_depth     target exon amino_acid\n",
      "0       1      0.991319  BARD1_X1A    1         M1\n",
      "1      10      0.988644  BARD1_X1A    1        R10\n",
      "2     100      0.951318  BARD1_X3A    3       Q100\n",
      "3     101      0.951693  BARD1_X3A    3       L101\n",
      "4     102      0.960612  BARD1_X3A    3       D102\n",
      "..    ...           ...        ...  ...        ...\n",
      "765    95      0.980482  BARD1_X3A    3        L95\n",
      "766    96      0.975715  BARD1_X3A    3        K96\n",
      "767    97      0.972879  BARD1_X3A    3        I97\n",
      "768    98      0.970115  BARD1_X3A    3        N98\n",
      "769    99      0.964458  BARD1_X3A    3        R99\n",
      "\n",
      "[770 rows x 5 columns], 'start_codon_scores':             target        pos allele     start_pos_id         Consequence  \\\n",
      "0    BARD1_X1A_ATG  214809490      A  ACG:214809490:A    missense_variant   \n",
      "1    BARD1_X1A_ATG  214809490      C  ACG:214809490:C    missense_variant   \n",
      "2    BARD1_X1A_ATG  214809490      G  ACG:214809490:G    missense_variant   \n",
      "3    BARD1_X1A_ATG  214809491      A  ACG:214809491:A         stop_gained   \n",
      "4    BARD1_X1A_ATG  214809491      G  ACG:214809491:G    missense_variant   \n",
      "..             ...        ...    ...              ...                 ...   \n",
      "142  BARD1_X1A_ATG  214809495      C  TAG:214809495:C  synonymous_variant   \n",
      "143  BARD1_X1A_ATG  214809495      T  TAG:214809495:T  synonymous_variant   \n",
      "144  BARD1_X1A_ATG  214809496      A  TAG:214809496:A    missense_variant   \n",
      "145  BARD1_X1A_ATG  214809496      C  TAG:214809496:C    missense_variant   \n",
      "146  BARD1_X1A_ATG  214809496      T  TAG:214809496:T    missense_variant   \n",
      "\n",
      "    AAsub canonical_start second_start     score  standard_error  ...  \\\n",
      "0    E27V             ACG          ATG  0.010524        0.010577  ...   \n",
      "1    E27G             ACG          ATG  0.020110        0.012341  ...   \n",
      "2    E27A             ACG          ATG  0.011019        0.014157  ...   \n",
      "3    E27*             ACG          ATG -0.201611        0.052975  ...   \n",
      "4    E27Q             ACG          ATG  0.009021        0.008595  ...   \n",
      "..    ...             ...          ...       ...             ...  ...   \n",
      "142  A25A             TAG          ATG  0.046398        0.011387  ...   \n",
      "143  A25A             TAG          ATG  0.030851        0.011251  ...   \n",
      "144  A25V             TAG          ATG  0.029821        0.008688  ...   \n",
      "145  A25G             TAG          ATG  0.034496        0.012131  ...   \n",
      "146  A25D             TAG          ATG  0.017403        0.012757  ...   \n",
      "\n",
      "    D05_rep3_count D05_rep3_freq  RNA_D05_rep2_count  RNA_D05_rep2_freq  \\\n",
      "0            20571      0.009794                9183           0.009874   \n",
      "1            13780      0.006561                5975           0.006424   \n",
      "2            11376      0.005416                5518           0.005933   \n",
      "3             3995      0.001902                2394           0.002574   \n",
      "4            23704      0.011286                9853           0.010594   \n",
      "..             ...           ...                 ...                ...   \n",
      "142          22234      0.010586                9525           0.010241   \n",
      "143          27767      0.013220               12434           0.013369   \n",
      "144          24409      0.011622                9855           0.010596   \n",
      "145          29746      0.014163               15269           0.016417   \n",
      "146          31351      0.014927               12239           0.013159   \n",
      "\n",
      "     D13_rep1_count  D13_rep1_freq  D05_rep1_count  D05_rep1_freq  \\\n",
      "0             31536       0.009051           40742       0.009537   \n",
      "1             20894       0.005997           25526       0.005975   \n",
      "2             21841       0.006268           26320       0.006161   \n",
      "3              3540       0.001016            7305       0.001710   \n",
      "4             42085       0.012078           52905       0.012384   \n",
      "..              ...            ...             ...            ...   \n",
      "142           48619       0.013954           39886       0.009337   \n",
      "143           45471       0.013050           50977       0.011933   \n",
      "144           46851       0.013446           51743       0.012112   \n",
      "145           71051       0.020392           72193       0.016899   \n",
      "146           46717       0.013408           65772       0.015396   \n",
      "\n",
      "     D13_rep3_count  D13_rep3_freq  \n",
      "0             31061       0.008560  \n",
      "1             26739       0.007369  \n",
      "2             18761       0.005171  \n",
      "3              3529       0.000973  \n",
      "4             37589       0.010360  \n",
      "..              ...            ...  \n",
      "142           40124       0.011058  \n",
      "143           59407       0.016373  \n",
      "144           45531       0.012548  \n",
      "145           59023       0.016267  \n",
      "146           60498       0.016673  \n",
      "\n",
      "[147 rows x 32 columns], 'orthogonal_data':      AAsub Adamovich2019_HDR Adamovich2019_western Lee2015_HDR  \\\n",
      "0    R641Q            Normal                Normal         NaN   \n",
      "1    R642G            Normal                Normal         NaN   \n",
      "2    G656R            Normal                Normal         NaN   \n",
      "3    S660R          Abnormal                Normal         NaN   \n",
      "4    R664T            Normal                Normal         NaN   \n",
      "..     ...               ...                   ...         ...   \n",
      "151  Q715A               NaN                   NaN         NaN   \n",
      "152  Y722F               NaN                   NaN         NaN   \n",
      "153  Y722A               NaN                   NaN         NaN   \n",
      "154  H723Y               NaN                   NaN         NaN   \n",
      "155  H723A               NaN                   NaN         NaN   \n",
      "\n",
      "    Dai2021_brca1foci Dai2021_bard1foci Dai2021_Ubbinding  \\\n",
      "0                 NaN               NaN               NaN   \n",
      "1                 NaN               NaN               NaN   \n",
      "2                 NaN               NaN               NaN   \n",
      "3                 NaN               NaN               NaN   \n",
      "4                 NaN               NaN               NaN   \n",
      "..                ...               ...               ...   \n",
      "151               NaN               NaN               NaN   \n",
      "152               NaN               NaN               NaN   \n",
      "153               NaN               NaN               NaN   \n",
      "154               NaN               NaN               NaN   \n",
      "155               NaN               NaN               NaN   \n",
      "\n",
      "    Witus2021_Ubactivity Becker2021_PARPiSensitivity  \n",
      "0                    NaN                         NaN  \n",
      "1                    NaN                         NaN  \n",
      "2                    NaN                         NaN  \n",
      "3                    NaN                         NaN  \n",
      "4                    NaN                         NaN  \n",
      "..                   ...                         ...  \n",
      "151                  NaN                      Normal  \n",
      "152                  NaN                      Normal  \n",
      "153                  NaN                      Normal  \n",
      "154                  NaN                      Normal  \n",
      "155                  NaN                      Normal  \n",
      "\n",
      "[156 rows x 9 columns]}\n"
     ]
    }
   ],
   "source": [
    "main(save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
